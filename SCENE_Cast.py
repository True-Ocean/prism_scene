#=============================================================
# ãƒ—ãƒªã‚ºãƒ ãƒ»ã‚·ãƒ¼ãƒ³ç†è«–ï¼ˆPRISM-SCENE Theoryï¼‰
# SCENEåˆ†æï¼ˆSystematic Character Extraction for Narrative Epilogueï¼‰
# SCENE_Caståˆ†æ
#=============================================================

#====================================================
# SCENE_Caståˆ†æã®æº–å‚™
#====================================================

# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æº–å‚™
from bs4 import BeautifulSoup
import google.genai as genai 
from dotenv import load_dotenv 
import os
import pandas as pd
from sqlalchemy import create_engine
from pydantic import BaseModel, Field # JSONã‚¹ã‚­ãƒ¼ãƒã®å®šç¾©ã«åˆ©ç”¨
from concurrent.futures import ThreadPoolExecutor # ä¸¦è¡Œå‡¦ç†ã«å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æº–å‚™
import My_Global as g

# PostgreSQLã®æ¥ç¶šè¨­å®š
dotenv_path = '/Users/trueocean/Desktop/Python_Code/Project_Key/.env'
load_dotenv(dotenv_path)

connection_config = {
    'user': os.getenv('DB_USER'),
    'password': os.getenv('DB_PASS'),
    'host': os.getenv('DB_HOST'),
    'port': os.getenv('DB_PORT'),
    'database': os.getenv('DB_NAME')
    }

engine = create_engine('postgresql://{user}:{password}@{host}:{port}/{database}'.format(**connection_config))


# APIã‚­ãƒ¼ã®è¨­å®šã¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
dotenv_path = "/Users/trueocean/Desktop/Python_Code/Project_Key/.env"
load_dotenv(dotenv_path) 
api_key = os.getenv('GEMINI_API_KEY')
client = genai.Client(api_key=api_key) 
MODEL = "gemini-2.5-flash" # é«˜é€Ÿãƒ¢ãƒ‡ãƒ«ã‚’ç¶­æŒ

print("APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†ï¼ˆãƒ¢ãƒ‡ãƒ«: gemini-2.5-flashï¼‰")


#====================================================
# ï¼•ä»£è¡€çµ±è¡¨ï¼ˆHTMLãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã‚’å …ç‰¢ã«èª­ã¿è¾¼ã‚€é–¢æ•°
#====================================================

def read_text_with_fallback(path, encodings=None):
    if encodings is None:
        encodings = ['utf-8', 'utf-8-sig', 'cp932', 'shift_jis', 'euc_jp', 'iso2022_jp', 'latin-1']
    last_exc = None
    with open(path, 'rb') as f:
        raw = f.read()
    for enc in encodings:
        try:
            return raw.decode(enc), enc
        except Exception as e:
            last_exc = e
    return raw.decode('utf-8', errors='replace'), 'utf-8 (forced replace)'


#====================================================
# HTMLã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–¢æ•°ã®å®šç¾©
#====================================================

def clean_html_for_analysis(html_content: str) -> str:
    """
    HTMLã‹ã‚‰ã€é¦¬ã®åŸºæœ¬æƒ…å ±ã€è¡€çµ±è¡¨ã®ãƒ‡ãƒ¼ã‚¿ã€ãŠã‚ˆã³ã‚¯ãƒ­ã‚¹æƒ…å ±ã‚’æŠ½å‡ºã—ã€
    HTMLã‚¿ã‚°ã‚’å‰Šé™¤ã—ã¦ç´”ç²‹ãªãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦çµåˆã—ã¾ã™ã€‚
    """
    soup = BeautifulSoup(html_content, 'lxml') 

    extracted_text = []

    # 1. <body>ã‚¿ã‚°å†…ã®å…¨ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
    #   -> ã“ã‚Œã«ã‚ˆã‚Šã€H3ã‚„æ€§åˆ¥/å¹´é½¢ãªã©ã®æƒ…å ±ãŒå«ã¾ã‚Œã¾ã™ã€‚
    #   -> ãŸã ã—ã€<table>ã‚¿ã‚°å†…ã®æƒ…å ±ã‚‚å«ã¾ã‚Œã‚‹ãŸã‚ã€å¾Œã§é‡è¤‡ã‚’é¿ã‘ã‚‹ã€‚
    
    if soup.body:
        # <body>ã‚¿ã‚°å†…ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ”¹è¡ŒåŒºåˆ‡ã‚Šã§å–å¾—
        # HTMLã®æ§‹é€ ä¸Šã€ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã«ã¯H3ã‚„æ€§åˆ¥/å¹´é½¢ã®æƒ…å ±ãŒå«ã¾ã‚Œã‚‹
        body_text_lines = soup.body.get_text('\n', strip=True).split('\n')
        
        # 2. åŸºæœ¬æƒ…å ±ãŒå«ã¾ã‚Œã‚‹æœ€åˆã®æ•°è¡Œã‚’æŠ½å‡º
        # ä»Šå›ã®æ§‹é€ ã§ã¯ã€<table>ã‚¿ã‚°ä»¥å‰ã®æƒ…å ±ã¯æœ€åˆã®æ•°è¡Œã«é›†ç´„ã•ã‚Œã¦ã„ã‚‹ã¯ãš
        # å®‰å…¨ã‚’è¦‹ã¦ã€æœ€åˆã®5è¡Œç¨‹åº¦ã‚’æŠ½å‡ºã—ã¾ã™
        for line in body_text_lines[:5]:
            line_stripped = line.strip()
            # æ—¢ã«æŠ½å‡ºæ¸ˆã¿ã®è¡€çµ±è¡¨ã®ã‚¯ãƒ­ã‚¹æƒ…å ±éƒ¨åˆ†ï¼ˆ[Hail to Reason]ãªã©ï¼‰ã¯é™¤å¤–ã™ã‚‹
            if not line_stripped.startswith('['):
                extracted_text.append(line_stripped)
        
    
    # 3. è¡€çµ±è¡¨ã®<table>ã‚¿ã‚°ã‚’ç‰¹å®šã™ã‚‹
    blood_table_tag = soup.find('table') 

    if blood_table_tag:
        
        # 4. ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä¸­ã®ç´”ç²‹ãªãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        # get_text() ã‚’ä½¿ç”¨ã—ã¦ã€<td>ã‚¿ã‚°å†…ã®é¦¬åã‚„æƒ…å ±ã ã‘ã‚’å–ã‚Šå‡ºã™
        # é‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ã€æŠ½å‡ºã•ã‚Œã‚‹ã®ã¯<table>ã‚¿ã‚°å†…éƒ¨ã®è¡€çµ±æƒ…å ±ã®ã¿
        table_text = blood_table_tag.get_text('\n', strip=True)
        extracted_text.append(table_text)

        # 5. ãƒ†ãƒ¼ãƒ–ãƒ«ã®ç›´å¾Œã«ã‚ã‚‹ã‚¯ãƒ­ã‚¹æƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹ (ä»¥å‰ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¶­æŒ)
        current_tag = blood_table_tag.next_sibling
        
        while current_tag:
            if isinstance(current_tag, str):
                text_content = current_tag.strip()
                if text_content:
                    extracted_text.append(text_content)
            elif current_tag.name is not None and current_tag.name not in ('br', 'font'):
                 break
            
            current_tag = current_tag.next_sibling
    
    # æŠ½å‡ºã—ãŸå…¨ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ”¹è¡Œã§çµåˆã—ã€éå‰°ãªç©ºç™½ã‚’æ•´ç†ã—ã¦è¿”ã—ã¾ã™
    return '\n'.join(extracted_text).strip()


#====================================================
# å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å®šç¾©ã™ã‚‹JSONã‚¹ã‚­ãƒ¼ãƒï¼ˆPydanticãƒ¢ãƒ‡ãƒ«ï¼‰
#====================================================

class AnalysisResult(BaseModel):
    """è¡€çµ±åˆ†æã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã€è‡ªå·±ç´¹ä»‹ã®çµæœã‚’æ ¼ç´ã™ã‚‹ã‚¹ã‚­ãƒ¼ãƒ"""
    è¡€çµ±åˆ†æ: str = Field(
        ..., 
        description="5ä»£è¡€çµ±è¡¨ã«å«ã¾ã‚Œã‚‹åé¦¬ã‚„ã‚¯ãƒ­ã‚¹ã«é–¢ã™ã‚‹ç°¡æ½”ãªåˆ†æçµæœã€‚åˆè¨ˆ200å­—ç¨‹åº¦ã€‚"
    )
    ã‚­ãƒ£ãƒ©è¨­å®š: str = Field(
        ..., 
        description="ã‚¿ã‚¤ãƒ—ã€å¤–è¦‹ã€æ€§æ ¼ã€ä¸€äººç§°ã€å£èª¿ã‚’å«ã‚€ã€ç°¡æ½”ãªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã€‚åˆè¨ˆ200å­—ç¨‹åº¦ã€‚"
    )
    è‡ªå·±ç´¹ä»‹: str = Field(
        ..., 
        description="è¨­å®šã«åŸºã¥ã„ãŸ200å­—ç¨‹åº¦ã®ç°¡æ½”ãªè‡ªå·±ç´¹ä»‹ã®ã‚»ãƒªãƒ•ã€‚ã€Œã€ã‚’å«ã‚€ã€‚"
    )


#====================================================
# Gemini API ã«ã‚ˆã‚‹ã‚­ãƒ£ãƒ©åˆ†æ
#====================================================

def analyze_single_horse(features_text, blood_text, race_info, max_retries=5):
    """
    ç‰¹å¾´ï¼ˆæ•°å€¤ãƒ‡ãƒ¼ã‚¿ï¼‰ã¨è¡€çµ±ãƒ†ã‚­ã‚¹ãƒˆã‚’çµ±åˆã—ã¦Geminiã«æ¸¡ã—ã€
    æ§‹é€ åŒ–ã•ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã€‚
    """
    
    analysis_prompt = f"""
    æä¾›ã•ã‚ŒãŸã€Œèƒ½åŠ›ãƒ‡ãƒ¼ã‚¿ã€ã¨ã€Œ5ä»£è¡€çµ±è¡¨ã€ã‚’åˆ†æã—ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

    ## ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    - å¯¾è±¡ãƒ¬ãƒ¼ã‚¹: {race_info}
    - é¦¬ã®èƒ½åŠ›ãƒ»ç‰¹å¾´ãƒ‡ãƒ¼ã‚¿: {features_text}
    - é¦¬ã®ï¼•ä»£è¡€çµ±ãƒ‡ãƒ¼ã‚¿: {blood_text}
    
    ## ã‚¿ã‚¹ã‚¯å†…å®¹ (æ—¥æœ¬èªã§å‡ºåŠ›)
    1. **è¡€çµ±ãƒ»èƒ½åŠ›åˆ†æ**: 
       è¡€çµ±èƒŒæ™¯ï¼ˆåé¦¬ã‚„ã‚¯ãƒ­ã‚¹ï¼‰ãŒã€ç¾åœ¨ã®èƒ½åŠ›æ•°å€¤ï¼ˆå…ˆè¡ŒæŒ‡æ•°ã€åŸºç¤èƒ½åŠ›ã€é©åˆç‡ç­‰ï¼‰ã«ã©ã†å½±éŸ¿ã—ã¦ã„ã‚‹ã‹ã€ç‰©èªçš„ã«åˆ†æã—ã¦ãã ã•ã„ï¼ˆ200å­—ç¨‹åº¦ï¼‰ã€‚
    2. **ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®š**: 
       åˆ†æçµæœã€æ€§åˆ¥ã€å¹´é½¢ã€æ¯›è‰²ã€ãã—ã¦ã€Œå‹è² æœè‰²ã€ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’è€ƒæ…®ã—ã€ã€Œã‚¿ã‚¤ãƒ—ã€ã€Œå¤–è¦‹ã€ã€Œæ€§æ ¼ã€ã€Œä¸€äººç§°ã€ã€Œå£èª¿ã€ã‚’æ§‹æˆã—ã¦ãã ã•ã„ï¼ˆ200å­—ç¨‹åº¦ï¼‰ã€‚
       ã€Œä¸€äººç§°ã€ã€Œå£èª¿ã€ã«ã¤ã„ã¦ã¯ã€æ€§åˆ¥ã€å¹´é½¢ï¼ˆ2æ­³ï¼šå¹¼ã„ã€3æ­³ï¼šè‹¥ã„ã€4æ­³ï¼šé’å¹´ã€5æ­³ï¼šæˆäººã€6æ­³ï¼šå£®å¹´ã€7æ­³ä»¥ä¸Šï¼šè€é½¢ï¼‰ã¨ã€è¡€çµ±ã‹ã‚‰æ¨å¯Ÿã•ã‚Œã‚‹å®¶ã®è‚²ã¡ã‚’è€ƒæ…®ã—ã¦ä¸‹ã•ã„ã€‚
       ï¼ˆå‚è€ƒï¼‰ä¸€äººç§°ã®å¹´é½¢é †: ã¼ãã€ã‚ãŸã—ã€ãŠã‚Œã€ã‚ãŸã„ã€ã†ã¡ã€ãŠã„ã‚‰ã€åƒ•ã€ç§ã€ä¿ºã€è‡ªåˆ†ã€æ‹™è€…ã€ã‚ã—ã€ã‚ã—ã‚ƒ ç­‰ã€‚å£èª¿ã®ä¾‹: ã§ã™ã¾ã™èª¿ã€ä¸å¯§ã€å„ªã—ã„ã€å³ã—ã„ã€é–¢è¥¿å¼ã€ãŠå¬¢æ§˜ã€ä¾ ç­‰ã€‚
    3. **è‡ªå·±ç´¹ä»‹**: 
       ä¸Šè¨˜è¨­å®šã«åŸºã¥ãã€ãƒ¬ãƒ¼ã‚¹ã¸è‡¨ã‚€æ±ºæ„ã‚’å«ã‚ãŸè‡ªå·±ç´¹ä»‹ã®ã‚»ãƒªãƒ•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼ˆ200å­—ç¨‹åº¦ï¼‰ã€‚

    å›ç­”ã¯å¿…ãšæŒ‡å®šã•ã‚ŒãŸJSONã‚¹ã‚­ãƒ¼ãƒã«å¾“ã£ã¦ãã ã•ã„ã€‚

    """

    for attempt in range(max_retries):
        try:
            response = client.models.generate_content(
                model=MODEL,
                contents=[analysis_prompt],
                config=genai.types.GenerateContentConfig(
                    response_mime_type="application/json",
                    response_schema=AnalysisResult,
                )
            )
            
            # response.parsed ã‚’ä½¿ã†ã¨ã€è‡ªå‹•çš„ã« AnalysisResult ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ãªã‚‹
            if response.parsed:
                return response.parsed.model_dump()
            # ã‚‚ã— response.text ã‹ã‚‰ãƒ‘ãƒ¼ã‚¹ã™ã‚‹å ´åˆã‚‚åŒæ§˜
            data_model = AnalysisResult.model_validate_json(response.text)
            return data_model.model_dump()
        
        except Exception as e:
            print(f"Retry {attempt+1}: Error {e}")
            if attempt == max_retries - 1: return None


#====================================================
# ä¸¦åˆ—å‡¦ç†ã«ã‚ˆã‚Šæ™‚é–“çŸ­ç¸®ã‚’å›³ã‚‹
#====================================================

def process_all_horses_parallel(df, max_workers=5):
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®å…¨é¦¬ã‚’ä¸¦åˆ—ã§åˆ†æã—ã€çµæœã‚’çµåˆã—ã¦è¿”ã™ã€‚
    max_workers: åŒæ™‚ã«å®Ÿè¡Œã™ã‚‹ã‚¹ãƒ¬ãƒƒãƒ‰æ•°ï¼ˆGeminiã®ç„¡æ–™æ ãªã‚‰5ã€œ8ç¨‹åº¦ãŒå®‰å®šï¼‰
    """
    # é‡è¤‡é˜²æ­¢ (æ—¢å­˜ã®ã‚«ãƒ©ãƒ ãŒã‚ã‚Œã°æ¶ˆã™) 
    target_cols = ['è¡€çµ±åˆ†æ', 'ã‚­ãƒ£ãƒ©è¨­å®š', 'è‡ªå·±ç´¹ä»‹']
    df = df.drop(columns=[c for c in target_cols if c in df.columns], errors='ignore')
    
    # 1é ­åˆ†ã®å‡¦ç†ã‚’ãƒ©ãƒƒãƒ—ã™ã‚‹é–¢æ•°
    def task(row_data):
        idx, row = row_data
        print(f" ğŸ{row['é¦¬å']}ã®åˆ†æé–‹å§‹...")
        result = analyze_single_horse(
            features_text=row['ç‰¹å¾´'],
            blood_text=row['è¡€çµ±æƒ…å ±'],
            race_info=Race_Info
        )
        if result:
            result['é¦¬å'] = row['é¦¬å']
            print(f" â­•ï¸{row['é¦¬å']}ã®åˆ†æå®Œäº†")
            return result
        else:
            print(f" âš ï¸{row['é¦¬å']}ã®åˆ†æå¤±æ•—")
            return None

    # ä¸¦åˆ—å®Ÿè¡Œã®é–‹å§‹
    print(f"--- SCENE_Caståˆ†æã®ä¸¦åˆ—å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆåŒæ™‚å®Ÿè¡Œæ•°: {max_workers}ï¼‰... ---")
    results = []
    
    # rowã‚’ãƒªã‚¹ãƒˆåŒ–ã—ã¦æ¸¡ã™
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # mapã‚’ä½¿ã£ã¦å…¨è¡Œã‚’ã‚¿ã‚¹ã‚¯ã¨ã—ã¦æŠ•å…¥
        rows = list(df.iterrows())
        results = list(executor.map(task, rows))

    # Noneï¼ˆå¤±æ•—ï¼‰ã‚’é™¤å»ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ åŒ–
    valid_results = [r for r in results if r is not None]
    res_df = pd.DataFrame(valid_results)
    
    # å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«çµåˆ
    final_df = pd.merge(df, res_df, on='é¦¬å', how='left')

    print(f"--- SCENE_Caståˆ†æã®ä¸¦åˆ—å‡¦ç†ã‚’å®Œäº†ã—ã¾ã—ãŸã€‚ ---")

    return final_df

#====================================================
# SCENE_Caståˆ†æã®å®Ÿè¡Œ
#====================================================

if __name__ == "__main__":

    # å¿…è¦æƒ…å ±ã®åé›†
    Race_Info = f'{g.stadium} {g.clas} {g.td} {g.distance}m {g.race_name}'
    SCENE_Script_df = pd.read_sql('SELECT * FROM "SCENE_Script"', con=engine)
    SCENE_Cast_df = SCENE_Script_df

    # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æŠ½å‡ºã—ãŸè¡€çµ±æƒ…å ±ã®æ ¼ç´
    blood_info_list = []
    for i in range(g.hr_num):
        blood_file = f'/Users/trueocean/Desktop/PRISM_SCENE/TFJV_Data/Blood{(i+1):02d}.html'
        file_text, used_encoding = read_text_with_fallback(blood_file)
        cleaned_text = clean_html_for_analysis(file_text) 
        blood_info_list.append(cleaned_text)
    SCENE_Cast_df['è¡€çµ±æƒ…å ±'] = blood_info_list

    # å„é¦¬ã®ã‚­ãƒ£ãƒ©è¨­å®šã‚’å®Ÿè¡Œ
    SCENE_Cast_df = process_all_horses_parallel(SCENE_Cast_df, max_workers=8)

    # çµæœã‚’PostgreSQLã«ä¿å­˜
    SCENE_Cast_df.to_sql('SCENE_Cast', con=engine, if_exists='replace', index=False)